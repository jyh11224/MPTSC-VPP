# MPTSC-VPP

[[Paper]]([https://arxiv.org/abs/2212.04356](https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11758932))
[[Colab example]](https://colab.research.google.com/github/openai/whisper/blob/master/notebooks/)

MPTSC-VPP is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.


## Approach

![image](https://github.com/jyh11224/MPTSC-VPP/assets/126738945/2de37bd4-7ae9-4d3d-bf4e-42f579cb2885)







## Requirements
- python
- sklearn
- tslearn
- numpy
- pandas
- matplotlib


## Command-line usage

## License

MPTSC-VPP's code is released under the MIT License. See [LICENSE]([https://github.com/openai/whisper/blob/main/LICENSE](https://github.com/jyh11224/MPTSC-VPP/blob/main/LICENSE)) for further details.
