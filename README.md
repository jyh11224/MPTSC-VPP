# MPTSC-VPP

[[Paper]](https://arxiv.org/abs/2212.04356)
[[Colab example]](https://colab.research.google.com/github/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb)

MPTSC-VPP is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.


## Approach

![image](https://github.com/jyh11224/MPTSC-VPP/assets/126738945/2de37bd4-7ae9-4d3d-bf4e-42f579cb2885)







## Requirements
- python
- sklearn
- tslearn
- numpy
- pandas
- matplotlib


## Command-line usage

## License

MPTSC-VPP's code is released under the MIT License. See [LICENSE](https://github.com/openai/whisper/blob/main/LICENSE) for further details.
